{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approche Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous proposons une approche élégante en utilisant les réseaux de neurones convolutionnels directements appliqués aux images issues des plot des landmarks.\n",
    "Cette approche élégante sera conduite de manière la plus optimisée possible.\n",
    "\n",
    "Il y a aura  deux types d'images :\n",
    "- les plot avec des points noirs\n",
    "- les plot avec les points colorés délimitant les différentes zones du visage (annotation manuelle des images)\n",
    "\n",
    "Ce notebook comprendra une approche directe (pas d'augmentation, pas/peu d'optimisation d'hyperparametres) et un approche avancée (data augmentation, architecture optimisée) et si le temps le permet du fine tuning ou transfert learning vers d'autres backbones plus avancés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA IS IN BLACK AND WHITE\n",
    "### Data generation and preprocessing\n",
    "## NO DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SUPER IMPORTANT TO EXECUTE OTHERWISE FACES MIGHT BE RGB\n",
    "import save_face_img\n",
    "\n",
    "save_face_img.create_faces(color_mode=\"bw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation NO AUGMENTATION\n",
    "train_datagen =         ImageDataGenerator(rescale=1./255)\n",
    "test_datagen =          ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator =       train_datagen.flow_from_directory(\n",
    "                        r'../CK+_lands/images/train/',\n",
    "                        target_size=(150, 150),\n",
    "                        batch_size=32,\n",
    "                        class_mode='categorical')\n",
    "\n",
    "validation_generator =  test_datagen.flow_from_directory(\n",
    "                        r'../CK+_lands/images/val/',\n",
    "                        target_size=(150, 150),\n",
    "                        batch_size=32,\n",
    "                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building / Compiling / Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "model =     Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compilation\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "pat = 5 #this is the number of epochs with no improvment after which the training will stop\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model, legend=True, scale_xy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=100, validation_data=validation_generator, callbacks=early_stopping) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('emotion_classifier_model.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('unit')\n",
    "plt.legend()\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('unit')\n",
    "plt.legend()\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen =          ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator =        test_datagen.flow_from_directory(\n",
    "                        r'../CK+_lands/images/test/',\n",
    "                        target_size=(150, 150),\n",
    "                        batch_size=1,\n",
    "                        class_mode='categorical')\n",
    "\n",
    "evaluation =            model.evaluate(test_generator)\n",
    "\n",
    "print(\"Test Loss:\", evaluation[0])\n",
    "print(\"Test Accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITH DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation and augmentation\n",
    "train_datagen_augmented =         ImageDataGenerator(rescale=1./255,\n",
    "                                        shear_range=0.2,\n",
    "                                        zoom_range=0.2,\n",
    "                                        horizontal_flip=True,\n",
    "                                        rotation_range=15,\n",
    "                                        width_shift_range=0.1,\n",
    "                                        height_shift_range=0.1)\n",
    "\n",
    "test_datagen =          ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator_augmented =       train_datagen_augmented.flow_from_directory(\n",
    "                        r'../CK+_lands/images/train/',\n",
    "                        target_size=(150, 150),\n",
    "                        batch_size=32,\n",
    "                        class_mode='categorical')\n",
    "\n",
    "validation_generator =  test_datagen.flow_from_directory(\n",
    "                        r'../CK+_lands/images/val/',\n",
    "                        target_size=(150, 150),\n",
    "                        batch_size=32,\n",
    "                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "model2 =     Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model2.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "model2.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "model2.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "model2.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compilation\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.fit(train_generator_augmented, epochs=100, validation_data=validation_generator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('unit')\n",
    "plt.legend()\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('unit')\n",
    "plt.legend()\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen =          ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator =        test_datagen.flow_from_directory(\n",
    "                        r'../CK+_lands/images/test/',\n",
    "                        target_size=(150, 150),\n",
    "                        batch_size=1,\n",
    "                        class_mode='categorical')\n",
    "\n",
    "evaluation =            model2.evaluate(test_generator)\n",
    "\n",
    "print(\"Test Loss:\", evaluation[0])\n",
    "print(\"Test Accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA HAS COLORED ZONES (cf report figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SUPER IMPORTANT TO EXECUTE OTHERWISE FACES MIGHT BE B&W\n",
    "import save_face_img\n",
    "\n",
    "save_face_img.create_faces(color_mode=\"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation NO AUGMENTATION\n",
    "train_datagen =         ImageDataGenerator(rescale=1./255)\n",
    "test_datagen =          ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator =       train_datagen.flow_from_directory(\n",
    "                        r'../CK+_lands/images/train/',\n",
    "                        target_size=(150, 150),\n",
    "                        batch_size=32,\n",
    "                        class_mode='categorical')\n",
    "\n",
    "validation_generator =  test_datagen.flow_from_directory(\n",
    "                        r'../CK+_lands/images/val/',\n",
    "                        target_size=(150, 150),\n",
    "                        batch_size=32,\n",
    "                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "model3 =     Sequential()\n",
    "model3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model3.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "model3.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model3.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "model3.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model3.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "model3.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model3.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compilation\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "pat = 5 #this is the number of epochs with no improvment after which the training will stop\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model3.fit(train_generator, epochs=100, validation_data=validation_generator, callbacks=early_stopping) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('unit')\n",
    "plt.legend()\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('unit')\n",
    "plt.legend()\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen =          ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator =        test_datagen.flow_from_directory(\n",
    "                        r'../CK+_lands/images/test/',\n",
    "                        target_size=(150, 150),\n",
    "                        batch_size=1,\n",
    "                        class_mode='categorical')\n",
    "\n",
    "evaluation =            model3.evaluate(test_generator)\n",
    "\n",
    "print(\"Test Loss:\", evaluation[0])\n",
    "print(\"Test Accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning via GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "def create_model(activation='relu'):\n",
    "    # for computational purposes we will use a very simple model\n",
    "    model3 =     Sequential()\n",
    "    model3.add(Conv2D(32, kernel_size=(3, 3), activation=activation,vinput_shape=(150, 150, 3)))\n",
    "    model3.add(MaxPool2D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "    model3.add(Flatten())\n",
    "    model3.add(Dense(256, activation=activation))\n",
    "    model3.add(Dropout(0.5))\n",
    "    model3.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    # Compilation\n",
    "    model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "batch_size = 1\n",
    "X_train, y_train = next(train_generator)\n",
    "X_val, y_val = next(validation_generator)\n",
    "for i in tqdm.tqdm(range(int(train_generator.n/batch_size)-1)): \n",
    "  img, label = next(train_generator)\n",
    "  X_train = np.append(X_train, img, axis=0 )\n",
    "  y_train = np.append(y_train, label, axis=0)\n",
    "for i in tqdm.tqdm(range(int(validation_generator.n/1)-1)): \n",
    "  img, label = next(validation_generator)\n",
    "  X_val = np.append(X_val, img, axis=0 )\n",
    "  y_val = np.append(y_val, label, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TOO LONG AND VERSION ISSUES WITH SCIKERAS AND PYTHON 8.\n",
    "# model = KerasClassifier(model=create_model, epochs=100, batch_size=10, verbose=0, callbacks=early_stopping)\n",
    "# # define the grid search parameters\n",
    "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "# param_grid = dict(model__activation=activation)\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "# # summarize results\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
